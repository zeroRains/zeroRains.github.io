<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Hierarchical Multi-Scale Attention for Semantic Segmentation | ZeroRains Blog</title><meta name="keywords" content="语义分割,层次注意力,SOTA"><meta name="author" content="zerorains,zerorainssakura@qq.com"><meta name="copyright" content="zerorains"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hierarchical Multi-Scale Attention for Semantic Segmentation  论文名称：Hierarchical Multi-Scale Attention for Semantic Segmentation 作者：Andrew Tao, Karan Sapra, Bryan Catanzaro 期刊：尚未查出（时间2020） 代码：https:&#x2F;&#x2F;g">
<meta property="og:type" content="article">
<meta property="og:title" content="Hierarchical Multi-Scale Attention for Semantic Segmentation">
<meta property="og:url" content="http://blog.zerorains.top/2021/08/17/Hierarchical-Multi-Scale-Attention-for-Semantic-Segmentation/index.html">
<meta property="og:site_name" content="ZeroRains Blog">
<meta property="og:description" content="Hierarchical Multi-Scale Attention for Semantic Segmentation  论文名称：Hierarchical Multi-Scale Attention for Semantic Segmentation 作者：Andrew Tao, Karan Sapra, Bryan Catanzaro 期刊：尚未查出（时间2020） 代码：https:&#x2F;&#x2F;g">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.zerorains.top/img/31.jpg">
<meta property="article:published_time" content="2021-08-17T02:24:19.000Z">
<meta property="article:modified_time" content="2022-06-30T08:17:58.115Z">
<meta property="article:author" content="zerorains">
<meta property="article:tag" content="语义分割">
<meta property="article:tag" content="层次注意力">
<meta property="article:tag" content="SOTA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.zerorains.top/img/31.jpg"><link rel="shortcut icon" href="/assets/favicon.ico"><link rel="canonical" href="http://blog.zerorains.top/2021/08/17/Hierarchical-Multi-Scale-Attention-for-Semantic-Segmentation/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-30 16:17:58'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/assets/apple-touch-icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">77</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">93</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/drink/"><i class="fa-fw fas fa-mug-hot"></i><span> 请我喝茶</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://ml.akasaki.space/"><i class="fa-fw fas fa-link"></i><span> DL笔记</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://notebook.therainisme.com/"><i class="fa-fw fas fa-link"></i><span> 急救箱</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/31.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">ZeroRains Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/drink/"><i class="fa-fw fas fa-mug-hot"></i><span> 请我喝茶</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://ml.akasaki.space/"><i class="fa-fw fas fa-link"></i><span> DL笔记</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://notebook.therainisme.com/"><i class="fa-fw fas fa-link"></i><span> 急救箱</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hierarchical Multi-Scale Attention for Semantic Segmentation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-08-17T02:24:19.000Z" title="发表于 2021-08-17 10:24:19">2021-08-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-06-30T08:17:58.115Z" title="更新于 2022-06-30 16:17:58">2022-06-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hierarchical Multi-Scale Attention for Semantic Segmentation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>Hierarchical Multi-Scale Attention for Semantic Segmentation</h1>
<blockquote>
<p>论文名称：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.10821">Hierarchical Multi-Scale Attention for Semantic Segmentation</a></p>
<p>作者：<a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+A">Andrew Tao</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sapra%2C+K">Karan Sapra</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Catanzaro%2C+B">Bryan Catanzaro</a></p>
<p>期刊：尚未查出（时间2020）</p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/semantic-segmentation">https://github.com/NVIDIA/semantic-segmentation</a></p>
</blockquote>
<h2 id="原文摘要">原文摘要</h2>
<blockquote>
<p>Multi-scale inference is commonly used to improve the results of semantic segmentation. Multiple images scales are passed through a network and then the results are combined with averaging or max pooling. In this work, we present an attention-based approach to combining multi-scale predictions. We show that predictions at certain scales are better at resolving particular failures modes, and that the network learns to favor those scales for such cases in order to generate better predictions. Our attention mechanism is hierarchical, which enables it to be roughly 4x more memory efficient to train than other recent approaches. In addition to enabling faster training, this allows us to train with larger crop sizes which leads to greater model accuracy. We demonstrate the result of our method on two datasets: Cityscapes and Mapillary Vistas. For Cityscapes, which has a large number of weakly labelled images, we also leverage auto-labelling to improve generalization. Using our approach we achieve a new state-of-the-art results in both Mapillary (61.1 IOU val) and Cityscapes (85.1 IOU test)</p>
</blockquote>
<h2 id="介绍">介绍</h2>
<p>语义分割的预测结果通常容易受到推理图像尺度的影响，如下图所示</p>
<p><img src="https://blog.zerorains.top/img/20210817104814image-20210817104813339.png" alt="image-20210817104813339"></p>
<p>在第一行中我们可以看到在图片尺度为0.5x(缩放到一半)的尺度下，路障的柱子的粗细分割结果显然不一致，但是在2.0x(放大两倍)的尺度下，路障的分割结果显然更好一些。</p>
<p>在第二行中我们可以看到在图片尺度为0.5x尺度下，道路的分割结果明显较好，但是在2.0x的尺度下，道路的分割结果就会多出一部分的内容。</p>
<p>本文将这种问题称为类混淆(class confusion)，使用多尺度推理(multi-scale inference)，将结果使用平均池化或最大池化联合起来，使得预测结果在一定范围内是有效的。使用平均值组联合多尺度通常能够促进分割结果，但是其面临将最差的分割结果与最好的分割结果结合的问题。最好的分割结果通常是使用不同尺度结果的加权组合。为了增加数据集中的方差，从而提高泛化能力，本文采用了一种自动在粗糙图像上标记的策略。与软标签策略相反，本文采用的是硬标签，以便管理标签的存储大小，这有助于通过降低磁盘IO成本，从而提高训练吞吐量。</p>
<p><strong>主要贡献</strong>：</p>
<ol>
<li>一种有效的分层多尺度注意力机制，有茱萸解决类别混淆和细节问题</li>
<li>一种基于硬阈值的i自动标签策略，利用未标记的图像并提高IOU</li>
</ol>
<h2 id="分层多尺度注意力-Hierarchical-multi-scale-attention">分层多尺度注意力(Hierarchical multi-scale attention)</h2>
<p>本文的注意力机制将从每一个维度学习密集的mask，这些多尺度的预测结果，h泽泻多尺度预测通过在mask之间进行像素a形成，然后在不同尺度之间进行像素求和来组合，以获取最终的结果。</p>
<p>在hierarchical方法中，不是为一个固定的尺度集合学习所有的注意力掩码(attention mask)，而是学习向量尺度之间的相对注意力掩码。当训练网络是，只用相邻的尺度对进行训练。在训练中使用了图像缩放的数据增强方法，这允许网络学习预测一系列尺度图片的相对注意力，当进行推理时，可以层次分明地应用学习到的注意力，将N个尺度的预测结果结合在一起。在本文中，优先考虑低尺度的预测,然后逐步上升到高u尺度的预测，因为他们有更多的全局背景，可以选择那些预测需要由高尺度的预测来完善。</p>
<p>该注意力可以用如下公式来表示</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi mathvariant="script">U</mi><mrow><mo fence="true">(</mo><msub><mi mathvariant="script">L</mi><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>=</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow></msub><mo>∗</mo><msub><mi>α</mi><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>=</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow></msub><mo fence="true">)</mo></mrow><mo>+</mo><mrow><mo fence="true">(</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><mi mathvariant="script">U</mi><mrow><mo fence="true">(</mo><msub><mi>α</mi><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>=</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo>∗</mo><msub><mi mathvariant="script">L</mi><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}_{(r=1)}=\mathcal{U}\left(\mathcal{L}_{(r=0.5)} * \alpha_{(r=0.5)}\right)+\left(\left(1-\mathcal{U}\left(\alpha_{(r=0.5)}\right)\right) * \mathcal{L}_{(r=1)}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">=</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2051999999999998em;vertical-align:-0.3551999999999999em;"></span><span class="mord mathcal" style="margin-right:0.09931em;">U</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">=</span><span class="mord mtight">0.5</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">=</span><span class="mord mtight">0.5</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2051999999999998em;vertical-align:-0.3551999999999999em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathcal" style="margin-right:0.09931em;">U</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">=</span><span class="mord mtight">0.5</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">=</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span></p>
<p>其中r = 1表示对图像不做任何操作，r=0.5表示下采样到原图的0.5倍，r=2上采样到原图的2倍，u表示双线性上采样操作，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">×</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">+</span></span></span></span>表示像素级别的乘法和加法，向网络主干中传递<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">r=0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0.5</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">r=1.0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1.0</span></span></span></span>两张图片，并由此产生每个尺度的语义逻辑(semantic logits)<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi></mrow><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathcal">L</span></span></span></span>和注意力掩码<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>，这两个用于生成最终的两个尺度之间的逻辑值(logits)<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi></mrow><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathcal">L</span></span></span></span></p>
<p><img src="https://blog.zerorains.top/img/20210818113751image-20210818113750576.png" alt="image-20210818113750576"></p>
<p>图中的Explicit方法出自论文<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.03339v2">Attention to scale: Scale-aware semanticimage segmentation</a>，其主要过程就是明确学习每个尺度的注意力，在Hierarchical方法中右上角是训练方式，网络通过右上角的结构学习预测相邻尺度之间的注意力，右下角以连锁/分级（Chained/Hierarchical）的方式进行推理，以结合多个尺度的预测。低尺度的注意力决定了下一个高尺度的注意力的贡献。</p>
<p>使用分层注意力机制有两个优势：</p>
<ol>
<li>在推理时，可以灵活地选择尺度，因此在用0.5x和1.0x训练的模型上增加新的尺度0.25x和2.0x，是可以通过之前提到的注意力机制链以分层的方式进行的，而在以前的方法中只限制与使用模型训练过哼中使用的相同比例。</li>
<li>与explicit方法相比，这种分层结构使我们能够提高训练效率，在explicit方法中，如果使用0.5,1.0,2.0的尺度，训练成本为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.</mn><msup><mn>5</mn><mn>2</mn></msup><mo>+</mo><mn>1.</mn><msup><mn>0</mn><mn>2</mn></msup><mo>+</mo><mn>2.</mn><msup><mn>0</mn><mn>2</mn></msup><mo>=</mo><mn>5.25</mn></mrow><annotation encoding="application/x-tex">0.5^{2}+1.0^{2}+2.0^{2}=5.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">0.</span><span class="mord"><span class="mord">5</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">1.</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2.</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5.25</span></span></span></span>，相对与但尺度训练，使用本文的分层方法，训练成本只有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.</mn><msup><mn>5</mn><mn>2</mn></msup><mo>+</mo><mn>1.</mn><msup><mn>0</mn><mn>2</mn></msup><mo>=</mo><mn>1.25</mn></mrow><annotation encoding="application/x-tex">0.5^{2}+1.0^{2}=1.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">0.</span><span class="mord"><span class="mord">5</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1.</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1.25</span></span></span></span>​</li>
</ol>
<h3 id="结构-Architecture">结构(Architecture)</h3>
<ol>
<li><strong>主干网络</strong>(Backbone)：在进行消融实验的过程中，本文使用的是ResNet-50(配置为输出步长等于8)作为算法的网络主干。对于SOTA的结果，本文使用更大，更强的主干HRNet-OCR(出自2019年的论文<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.11065v4">Object-contextual representations for semantic segmentation</a>)</li>
<li><strong>语义头</strong>(Semantic Head)：语义预测是由一个全卷积头进行的，其构成为：3x3Conv-&gt;BN-&gt;ReLU-&gt;3x3Conv-&gt;BN-&gt;ReLU-&gt;1x1Conv，最后一层卷积输出的通道数为数据集的类别数</li>
<li><strong>注意力头</strong>(Attention Head)：注意力预测是通过一个单独的头来完成的，该头在结构上与语义头相同，除了最后的卷积输出，他输出的是一个单通道的特征图。当使用ResNet-50作为主干时，语义头和注意力头的输入都是ResNet-50的最后阶段的特征图，当使用HRNet-OCR时，语义头和注意力头的输入是OCR块的特征图。在HRNetOCR中，还存在一个辅助语义头，他在OCR之前直接从HRNet主干中获取其特征。注意力头的结构可以表示为：1x1Conv-&gt;BN-&gt;ReLU-&gt;1x1Conv，在对语义逻辑生成注意力后，预测结果被双线性上采样至目标图像的尺寸。</li>
</ol>
<h2 id="Cityscapes上的自动标记-Auto-Labelling-on-Cityscapes">Cityscapes上的自动标记(Auto Labelling on Cityscapes)</h2>
<p>受到关于图像分类任务自动标记工作的启发，本文在Cityscapes上采用了自动标记策略，以提高有效数据集的规模和标记质量。在Cityscpaes中，用20000张粗略标记的图像，以及3500张精细标记的图像。粗略图像的标签质量非常一般，并且包含了大量的未标记元素。但是经过本文的自动标签方法，可以提高标签的质量，这反过来又有助于模型的IOU指标。如下图所示，左边表示原图，中间是粗糙的标记，右边是自动标记优化后的结果</p>
<p><img src="https://blog.zerorains.top/img/20210818141216image-20210818141215561.png" alt="image-20210818141215561"></p>
<p>在本文中，采用了硬标签策略(hard labelling strategy)，即对于一个给定的像素，我们选择有teacher网络预测出的最高概率的类别。根据teacher网络的输出概率来确定标签的阈值。超过阈值的teacher网络预测结果将成为真正的标签，否则该像素被标记为ignore class，在实际使用过程中，本文使用的阈值为0.9</p>
<h2 id="实现细节">实现细节</h2>
<h3 id="训练细节">训练细节</h3>
<p>在Nvidia DGX服务器上使用pytorch进行训练，使用SGD作为优化其，在每个GPU上的BatchSize为1，momentum为0.9，权重衰减(weight decay)为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><msup><mi>e</mi><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">5e^{-4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span>。采用多项式(polynomial)学习率策略。使用RMI(出自论文<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.12037">Region mutual information loss for semantic segmentation</a>)作为默认设置下的主要损失函数,并使用交叉熵作为辅助损失函数，对于Cityscapes，使用2.0的poly指数，初始学习率为0.01，在2DGX节点上训练了175个epoch。对于Mapillary数据集，使用1.0的poly指数，0.02的初始学习率，并在4个DGXn解嗲上训练了200个脉冲。在数据加载其中使用类的统一采用，从每个类中频均采样，这有助于在数据分布不均的情况下改善结果。</p>
<h3 id="数据增强">数据增强</h3>
<p>在输入图像上采用高斯模糊(gaussian blur)，颜色增强(color augmentation)，随机水平翻转(random horizontal flip)和随机缩放(random scaling)（0.5x~2.0x）来增加训练过程中的数据集。对于cityscapes数据集，使用2048x1024的裁剪尺寸，对于Mapillary使用1856x1024的裁剪尺寸</p>
<h2 id="cityscpaes结果">cityscpaes结果</h2>
<p><img src="https://blog.zerorains.top/img/20210818145116image-20210818145114756.png" alt="image-20210818145114756"></p>
<h2 id="Mapillary-Vistas结果">Mapillary Vistas结果</h2>
<p><img src="https://blog.zerorains.top/img/20210818145138image-20210818145135609.png" alt="image-20210818145135609"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:zerorainssakura@qq.com">zerorains</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://blog.zerorains.top/2021/08/17/Hierarchical-Multi-Scale-Attention-for-Semantic-Segmentation/">http://blog.zerorains.top/2021/08/17/Hierarchical-Multi-Scale-Attention-for-Semantic-Segmentation/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://blog.zerorains.top" target="_blank">ZeroRains Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/">语义分割</a><a class="post-meta__tags" href="/tags/%E5%B1%82%E6%AC%A1%E6%B3%A8%E6%84%8F%E5%8A%9B/">层次注意力</a><a class="post-meta__tags" href="/tags/SOTA/">SOTA</a></div><div class="post_share"><div class="social-share" data-image="/img/31.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/08/18/Object-Contextual-Representations-for-Semantic-Segmentation/"><img class="prev-cover" src="/img/27.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Object-Contextual Representations for Semantic Segmentation</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"><img class="next-cover" src="/img/4.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">计算机网络（三）——数据链路层</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/08/18/Object-Contextual-Representations-for-Semantic-Segmentation/" title="Object-Contextual Representations for Semantic Segmentation"><img class="cover" src="/img/27.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-18</div><div class="title">Object-Contextual Representations for Semantic Segmentation</div></div></a></div><div><a href="/2021/05/17/BiSeNet实时语义分割/" title="BiSeNet实时语义分割"><img class="cover" src="/img/20210505093832image-20210505093830789.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="title">BiSeNet实时语义分割</div></div></a></div><div><a href="/2021/09/03/FaPN-Feature-aligned-Pyramid-Network-for-Dense-Image-Prediction/" title="FaPN-Feature-aligned Pyramid Network for Dense Image Prediction"><img class="cover" src="/img/1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-03</div><div class="title">FaPN-Feature-aligned Pyramid Network for Dense Image Prediction</div></div></a></div><div><a href="/2021/09/01/Global-Aggregation-then-Local-Distribution-in-Fully-Convolutional-Networks/" title="Global Aggregation then Local Distribution in Fully Convolutional Networks"><img class="cover" src="/img/18.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-01</div><div class="title">Global Aggregation then Local Distribution in Fully Convolutional Networks</div></div></a></div><div><a href="/2021/05/11/Fast-SCNN快速语义分割/" title="Fast-SCNN快速语义分割"><img class="cover" src="/img/17.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-11</div><div class="title">Fast-SCNN快速语义分割</div></div></a></div><div><a href="/2021/08/25/Region-Mutual-Information-Loss-for-Semantic-Segmentation/" title="Region Mutual Information Loss for Semantic Segmentation"><img class="cover" src="/img/10.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-25</div><div class="title">Region Mutual Information Loss for Semantic Segmentation</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/assets/apple-touch-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">zerorains</div><div class="author-info__description">No matter what happens, I will do my best.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">77</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">93</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zeroRains"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="tencent://message?uin=2274033547" target="_blank" title="qq"><i class="fab fa-qq"></i></a><a class="social-icon" href="https://github.com/zeroRains" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zerorainssakura@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://blog.csdn.net/kiminoamae?spm=1000.2115.3001.5343" target="_blank" title="csdn"><i class="fab fa-cuttlefish"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">未来主要研究方向。。。算了还是先学好基础。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Hierarchical Multi-Scale Attention for Semantic Segmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%9F%E6%96%87%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">原文摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%B3%A8%E6%84%8F%E5%8A%9B-Hierarchical-multi-scale-attention"><span class="toc-number">1.3.</span> <span class="toc-text">分层多尺度注意力(Hierarchical multi-scale attention)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84-Architecture"><span class="toc-number">1.3.1.</span> <span class="toc-text">结构(Architecture)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Cityscapes%E4%B8%8A%E7%9A%84%E8%87%AA%E5%8A%A8%E6%A0%87%E8%AE%B0-Auto-Labelling-on-Cityscapes"><span class="toc-number">1.4.</span> <span class="toc-text">Cityscapes上的自动标记(Auto Labelling on Cityscapes)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="toc-number">1.5.</span> <span class="toc-text">实现细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82"><span class="toc-number">1.5.1.</span> <span class="toc-text">训练细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">1.5.2.</span> <span class="toc-text">数据增强</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#cityscpaes%E7%BB%93%E6%9E%9C"><span class="toc-number">1.6.</span> <span class="toc-text">cityscpaes结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mapillary-Vistas%E7%BB%93%E6%9E%9C"><span class="toc-number">1.7.</span> <span class="toc-text">Mapillary Vistas结果</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/10/12/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89/" title="「书籍阅读」分布式计算系统（二）"><img src="/img/31.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="「书籍阅读」分布式计算系统（二）"/></a><div class="content"><a class="title" href="/2022/10/12/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89/" title="「书籍阅读」分布式计算系统（二）">「书籍阅读」分布式计算系统（二）</a><time datetime="2022-10-12T09:18:04.000Z" title="发表于 2022-10-12 17:18:04">2022-10-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/09/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" title="「书籍阅读」分布式计算系统（一）"><img src="/img/19.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="「书籍阅读」分布式计算系统（一）"/></a><div class="content"><a class="title" href="/2022/10/09/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" title="「书籍阅读」分布式计算系统（一）">「书籍阅读」分布式计算系统（一）</a><time datetime="2022-10-09T01:53:02.000Z" title="发表于 2022-10-09 09:53:02">2022-10-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/01/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" title="「书籍阅读」数据密集型应用系统设计"><img src="/img/14.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="「书籍阅读」数据密集型应用系统设计"/></a><div class="content"><a class="title" href="/2022/10/01/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" title="「书籍阅读」数据密集型应用系统设计">「书籍阅读」数据密集型应用系统设计</a><time datetime="2022-10-01T06:39:00.000Z" title="发表于 2022-10-01 14:39:00">2022-10-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/29/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" title="「书籍阅读」智能计算系统"><img src="/img/18.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="「书籍阅读」智能计算系统"/></a><div class="content"><a class="title" href="/2022/09/29/%E3%80%8C%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%8D%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" title="「书籍阅读」智能计算系统">「书籍阅读」智能计算系统</a><time datetime="2022-09-29T09:10:17.000Z" title="发表于 2022-09-29 17:10:17">2022-09-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/18/%E3%80%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%8DNetRL-Task-aware-Network-Denoising-via-Deep-Reinforcement-Learning/" title="「论文阅读」NetRL: Task-aware Network Denoising via Deep Reinforcement Learning"><img src="/img/17.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="「论文阅读」NetRL: Task-aware Network Denoising via Deep Reinforcement Learning"/></a><div class="content"><a class="title" href="/2022/09/18/%E3%80%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%8DNetRL-Task-aware-Network-Denoising-via-Deep-Reinforcement-Learning/" title="「论文阅读」NetRL: Task-aware Network Denoising via Deep Reinforcement Learning">「论文阅读」NetRL: Task-aware Network Denoising via Deep Reinforcement Learning</a><time datetime="2022-09-18T09:26:22.000Z" title="发表于 2022-09-18 17:26:22">2022-09-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By zerorains</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>